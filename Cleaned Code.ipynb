{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "152b82c2-d934-40f2-911b-2526b01ddc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smartsheet client initialized.\n",
      "\n",
      "--- Processing Sheet: Bainbridge Permit Tracking Sheet (ID: 595984821211012) ---\n",
      "Total NON-BLANK rows added to DataFrame: 20\n",
      "\n",
      "--- Processing Sheet: Burnt Hill Farm Permit Tracking Sheet (ID: 434783269113732) ---\n",
      "Total NON-BLANK rows added to DataFrame: 0\n",
      "\n",
      "--- Processing Sheet: Loch Raven Permit Tracking Sheet (ID: 8555094548107140) ---\n",
      "Total NON-BLANK rows added to DataFrame: 2\n",
      "\n",
      "--- Processing Sheet: Pimlico Permit Tracking Sheet (ID: 8603266901299076) ---\n",
      "Total NON-BLANK rows added to DataFrame: 13\n",
      "\n",
      "--- Processing Sheet: Quantum Permit Tracking Sheet (ID: 2274508036591492) ---\n",
      "Total NON-BLANK rows added to DataFrame: 28\n",
      "\n",
      "--- Processing Sheet: SBY Market Permit Tracking Sheet (ID: 6312015061536644) ---\n",
      "Total NON-BLANK rows added to DataFrame: 9\n",
      "\n",
      "==================================================\n",
      "Compilation Complete! Total Sheets Compiled: 5\n",
      "Final DataFrame shape: (72, 31)\n",
      "==================================================\n",
      "\n",
      "Starting date standardization...\n",
      "Date Standardization Complete. Columns are now Datetime Objects.\n",
      "\n",
      "Starting business day and expiration calculations...\n",
      "Calculated ELAPSED business days for 'Submitted Date'.\n",
      "Calculated ELAPSED business days for 'Communication Start Date'.\n",
      "Calculated ELAPSED business days for 'Initial Assessment Date'.\n",
      "Calculated ELAPSED business days for 'Review Start Date'.\n",
      "Calculated ELAPSED business days for 'Final Resolution Date'.\n",
      "Calculated REMAINING days for 'Expiration Date'.\n",
      "\n",
      "Starting calculations for business days between milestones...\n",
      "Calculated business days for 'Submitted Date' to 'Communication Start Date'.\n",
      "Calculated business days for 'Submitted Date' to 'Initial Assessment Date'.\n",
      "Calculated business days for 'Submitted Date' to 'Review Start Date'.\n",
      "Calculated business days for 'Submitted Date' to 'Final Resolution Date'.\n",
      "Calculated business days for 'Communication Start Date' to 'Initial Assessment Date'.\n",
      "Calculated business days for 'Communication Start Date' to 'Review Start Date'.\n",
      "Calculated business days for 'Communication Start Date' to 'Final Resolution Date'.\n",
      "Calculated business days for 'Initial Assessment Date' to 'Review Start Date'.\n",
      "Calculated business days for 'Initial Assessment Date' to 'Final Resolution Date'.\n",
      "Calculated business days for 'Review Start Date' to 'Final Resolution Date'.\n",
      "All new day-difference calculations complete.\n",
      "Conversion of calculated columns to whole numbers complete.\n",
      "\n",
      "--- Converting Date Objects back to ISO strings for export. ---\n",
      "Final Calculated DataFrame saved to 'calculated_smartsheet_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import smartsheet\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytz\n",
    "from datetime import date, timedelta, datetime\n",
    "import holidays as pyholidays\n",
    "from socrata_replace.socrata_py_replace import ReplaceBot\n",
    "from secret_data import userpass\n",
    "from datetime import date \n",
    "\n",
    "# =================================================================\n",
    "# === CONFIGURATION & CREDENTIALS ===\n",
    "# =================================================================\n",
    "\n",
    "SMARTSHEET_ACCESS_TOKEN = \"74xq6QRJHXtN4VdRbwCl9rJeznxjgBcKEPJeJ\"\n",
    "TARGET_TZ = 'US/Eastern'\n",
    "eastern_tz = pytz.timezone(TARGET_TZ)\n",
    "\n",
    "today_tz_aware = pd.to_datetime(date.today()).tz_localize(eastern_tz).normalize()\n",
    "RAW_OUTPUT_FILENAME = 'compiled_smartsheet_data_raw.csv'\n",
    "CALCULATED_OUTPUT_FILENAME = 'calculated_smartsheet_data.csv'\n",
    "\n",
    "PORTAL = \"data.maryland.gov\"\n",
    "DATASET_UID = 'b4mc-xw4p'\n",
    "\n",
    "try:\n",
    "    smartsheet_client = smartsheet.Smartsheet(SMARTSHEET_ACCESS_TOKEN)\n",
    "    print(\"Smartsheet client initialized.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Smartsheet client. Details: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Base columns for all date processing\n",
    "DATE_COLUMNS = [\n",
    "    'Submitted Date',\n",
    "    'Communication Start Date',\n",
    "    'Initial Assessment Date',\n",
    "    'Review Start Date',\n",
    "    'Final Resolution Date',\n",
    "    'Expiration Date'\n",
    "]\n",
    "\n",
    "\n",
    "ELAPSED_DATE_COLUMNS = DATE_COLUMNS[:-1]\n",
    "\n",
    "EXPIRATION_COLUMN = DATE_COLUMNS[-1] \n",
    "\n",
    "MILESTONE_DATE_COLUMNS = DATE_COLUMNS[:-1]\n",
    "# =================================================================\n",
    "# === FUNCTION DEFINITIONS ===\n",
    "# =================================================================\n",
    "\n",
    "def get_sheet_id_by_name(sheet_name):\n",
    "    \"\"\" Finds the ID of a sheet given its name. \"\"\"\n",
    "    if not sheet_name: return None\n",
    "    try:\n",
    "        response = smartsheet_client.Sheets.list_sheets(include_all=True)\n",
    "        for sheet in response.data:\n",
    "            if sheet.name.strip() == sheet_name.strip():\n",
    "                return sheet.id\n",
    "    except smartsheet.exceptions.ApiError as e:\n",
    "        print(f\"API Error finding sheet ID for '{sheet_name}': {e.error.message}\")\n",
    "    return None\n",
    "\n",
    "def get_sheet_data(sheet_id):\n",
    "    \"\"\" Retrieves the full row and cell data for a specific sheet ID and returns it as a pandas DataFrame. \"\"\"\n",
    "    try:\n",
    "        sheet_object=smartsheet_client.Sheets.get_sheet(sheet_id)\n",
    "    except smartsheet.exceptions.ApiError as e:\n",
    "        print(e.error.message)\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"\\n--- Processing Sheet: {sheet_object.name} (ID: {sheet_id}) ---\")\n",
    "    column_map = {col.id: col.title for col in sheet_object.columns}\n",
    "    column_titles = list(column_map.values())\n",
    "    all_rows_data = []\n",
    "    \n",
    "    for row in sheet_object.rows:\n",
    "        row_data = {}\n",
    "        has_data = False\n",
    "        for cell in row.cells:\n",
    "            column_title = column_map.get(cell.column_id, \"Unknown Column\")\n",
    "            value = cell.display_value if cell.display_value is not None else cell.value\n",
    "            row_data[column_title] = value\n",
    "            if value is not None and value != '':\n",
    "                has_data = True\n",
    "                \n",
    "        if has_data:\n",
    "            all_rows_data.append(row_data)\n",
    "            \n",
    "    print(f\"Total NON-BLANK rows added to DataFrame: {len(all_rows_data)}\")\n",
    "    df = pd.DataFrame(all_rows_data, columns=column_titles)\n",
    "    df['Sheet Name'] = sheet_object.name\n",
    "    df['Sheet ID'] = sheet_id\n",
    "    return df\n",
    "\n",
    "def count_maryland_business_days(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Calculates the total number of business days (Mon-Fri, excluding \n",
    "    US federal and Maryland state holidays) between a start_date and an end_date.\n",
    "    \n",
    "    Returns the difference in business days (End Date - Start Date).\n",
    "    \"\"\"\n",
    "    if not (isinstance(start_date, date) and isinstance(end_date, date)):\n",
    "        return np.nan\n",
    "        \n",
    "    if pd.isna(start_date) or pd.isna(end_date):\n",
    "        return np.nan\n",
    "\n",
    "    if start_date > end_date:\n",
    "        return np.nan \n",
    "\n",
    "    md_holidays = pyholidays.US(state='MD', years=range(start_date.year, end_date.year + 2))\n",
    "\n",
    "    business_day_count = 0\n",
    "    current_date = start_date + timedelta(days=1)\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        is_weekend = current_date.weekday() >= 5 \n",
    "        is_holiday = current_date in md_holidays\n",
    "        \n",
    "        if not is_weekend and not is_holiday:\n",
    "            business_day_count += 1\n",
    "            \n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return business_day_count\n",
    "\n",
    "# =================================================================\n",
    "# === DATA RETRIEVAL AND INITIAL CLEANUP ===\n",
    "# =================================================================\n",
    "\n",
    "all_dfs = []\n",
    "csv_name = 'Sheet Names.csv'\n",
    "try:\n",
    "    df_names = pd.read_csv(csv_name)\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Error: Required file '{csv_name}' not found.\")\n",
    "    exit()\n",
    "\n",
    "for names in df_names['Sheet Name']:\n",
    "    sheet_id = get_sheet_id_by_name(names)\n",
    "    if sheet_id:\n",
    "        current_df = get_sheet_data(sheet_id)\n",
    "        if not current_df.empty:\n",
    "            all_dfs.append(current_df)\n",
    "\n",
    "if all_dfs:\n",
    "    final_compiled_df = pd.concat(all_dfs, ignore_index=True, sort=False)\n",
    "    final_compiled_df.fillna('', inplace=True)\n",
    "    \n",
    "    \n",
    "    final_compiled_df['Duration'] = final_compiled_df['Duration'].replace('', np.nan)\n",
    "    final_compiled_df['Duration_Cleaned'] = final_compiled_df['Duration'].astype(str).str.replace('d', '', regex=False)\n",
    "    final_compiled_df['Duration_Days'] = pd.to_numeric(final_compiled_df['Duration_Cleaned'], errors='coerce')\n",
    "    final_compiled_df['Duration'] = final_compiled_df['Duration_Days'].astype('Int64')\n",
    "    final_compiled_df = final_compiled_df.drop(['Duration_Days', 'Duration_Cleaned'], axis=1)\n",
    "    \n",
    "    \n",
    "    final_compiled_df.to_csv(RAW_OUTPUT_FILENAME, index=False, encoding='utf-8')\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Compilation Complete! Total Sheets Compiled: {len(all_dfs)}\")\n",
    "    print(f\"Final DataFrame shape: {final_compiled_df.shape}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "else:\n",
    "    print(\"\\n--- No sheets were successfully compiled. Exiting. ---\")\n",
    "    exit()\n",
    "\n",
    "# =================================================================\n",
    "# === DATE STANDARDIZATION (CRITICAL STEP 1) ===\n",
    "# =================================================================\n",
    "# This converts columns to Datetime Objects, which is necessary for the next step.\n",
    "\n",
    "print(\"\\nStarting date standardization...\")\n",
    "df_processed = final_compiled_df.copy() \n",
    "\n",
    "for col in DATE_COLUMNS:\n",
    "    \n",
    "    df_processed[col] = pd.to_datetime(\n",
    "        df_processed[col],\n",
    "        errors='coerce',\n",
    "        utc=True\n",
    "    )\n",
    "    \n",
    "    if pd.api.types.is_datetime64_any_dtype(df_processed[col]):\n",
    "        df_processed[col] = df_processed[col].dt.tz_convert(TARGET_TZ)\n",
    "    else:\n",
    "        df_processed[col] = pd.NaT\n",
    "\n",
    "print(\"Date Standardization Complete. Columns are now Datetime Objects.\")\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# === BUSINESS DAY CALCULATION (CRITICAL STEP 2) ===\n",
    "# =================================================================\n",
    "\n",
    "# --- CRITICAL STEP 2: CALCULATE BUSINESS DAYS AND EXPIRATION DAYS ---\n",
    "\n",
    "\n",
    "today_date = pd.to_datetime(date.today()) \n",
    "\n",
    "print(\"\\nStarting business day and expiration calculations...\")\n",
    "\n",
    "\n",
    "for start_col in ELAPSED_DATE_COLUMNS:\n",
    "    \n",
    "    new_col_name = start_col.replace(' Date', '').replace(' ', '_').lower() + \"_business_days_to_today\"\n",
    "    \n",
    "    df_processed[new_col_name] = df_processed.apply(\n",
    "        lambda row: count_maryland_business_days(\n",
    "            row[start_col].date(),\n",
    "            date.today()\n",
    "        )\n",
    "        if pd.notna(row[start_col]) else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    print(f\"Calculated ELAPSED business days for '{start_col}'.\")\n",
    "\n",
    "# --- 2B. REMAINING/OVERDUE Days (Today -> Expiration Date) ---\n",
    "\n",
    "\n",
    "expiration_col_name = EXPIRATION_COLUMN.replace(' Date', '').replace(' ', '_').lower() + \"_days_remaining\"\n",
    "\n",
    "df_processed[expiration_col_name] = (\n",
    "    df_processed[EXPIRATION_COLUMN].dt.normalize() - today_tz_aware\n",
    ").dt.days\n",
    "\n",
    "df_processed[expiration_col_name] = df_processed[expiration_col_name].astype('Int64')\n",
    "\n",
    "print(f\"Calculated REMAINING days for '{EXPIRATION_COLUMN}'.\")\n",
    "\n",
    "# =================================================================\n",
    "# === NEW SECTION: 2C. DAYS BETWEEN MILESTONES (BUSINESS DAYS) ===\n",
    "# =================================================================\n",
    "\n",
    "print(\"\\nStarting calculations for business days between milestones...\")\n",
    "\n",
    "\n",
    "for i in range(len(MILESTONE_DATE_COLUMNS)):\n",
    "    for j in range(i + 1, len(MILESTONE_DATE_COLUMNS)):\n",
    "        start_col = MILESTONE_DATE_COLUMNS[i]\n",
    "        end_col = MILESTONE_DATE_COLUMNS[j]\n",
    "\n",
    "        start_name = start_col.replace(' Date', '').replace(' ', '_').lower()\n",
    "        end_name = end_col.replace(' Date', '').replace(' ', '_').lower()\n",
    "        new_col_name = f\"{start_name}_to_{end_name}_business_days\"\n",
    "\n",
    "        df_processed[new_col_name] = df_processed.apply(\n",
    "            lambda row: count_maryland_business_days(\n",
    "                row[start_col].date(),\n",
    "                row[end_col].date()\n",
    "            )\n",
    "            if pd.notna(row[start_col]) and pd.notna(row[end_col]) else np.nan,\n",
    "            axis=1\n",
    "        )\n",
    "        print(f\"Calculated business days for '{start_col}' to '{end_col}'.\")\n",
    "\n",
    "all_calculated_cols_new = [col for col in df_processed.columns if col.endswith(\"_business_days\")]\n",
    "print(\"All new day-difference calculations complete.\")\n",
    "\n",
    "all_calculated_cols = [\n",
    "    col for col in df_processed.columns\n",
    "    if col.endswith(\"_business_days_to_today\") or col.endswith(\"_days_remaining\") or col.endswith(\"_business_days\")\n",
    "]\n",
    "\n",
    "for col in all_calculated_cols:\n",
    "    df_processed[col] = df_processed[col].astype('Int64', errors='ignore')\n",
    "\n",
    "print(\"Conversion of calculated columns to whole numbers complete.\")\n",
    "\n",
    "print(\"\\n--- Converting Date Objects back to ISO strings for export. ---\")\n",
    "for col in DATE_COLUMNS:\n",
    "    if pd.api.types.is_datetime64_any_dtype(df_processed[col]):\n",
    "        df_processed[col] = df_processed[col].apply(\n",
    "            lambda x: x.isoformat() if pd.notna(x) else np.nan\n",
    "        )\n",
    "    \n",
    "df_processed.to_csv(CALCULATED_OUTPUT_FILENAME, index=False, encoding='utf-8')\n",
    "print(f\"Final Calculated DataFrame saved to '{CALCULATED_OUTPUT_FILENAME}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f73239f4-d785-4c64-a9b8-09cb497077e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portal = \"data.maryland.gov\"\n",
    "uid='b4mc-xw4p'\n",
    "rb = ReplaceBot(False, data_folder=\"\", filename=RAW_OUTPUT_FILENAME, socrata_server=portal)\n",
    "rb.upload_replacement(uid, 'private', filename=RAW_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28756527-be28-445e-b535-dbaa61e570b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portal = \"data.maryland.gov\"\n",
    "uid='ijd9-i3sp'\n",
    "rb = ReplaceBot(False, data_folder=\"\", filename=CALCULATED_OUTPUT_FILENAME, socrata_server=portal)\n",
    "rb.upload_replacement(uid, 'private', filename=CALCULATED_OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f4d521f-bbd9-4e6b-abb5-faaae00aa3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created 'index.html' with the interactive Plotly Gantt chart.\n",
      "The file is ready for embedding in your Socrata/ArcGIS Dashboard.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import datetime as dt\n",
    "\n",
    "# --- 1. Prepare Data for Plotly (using a list of dictionaries/DataFrame) ---\n",
    "\n",
    "# Sample data for tasks (dates can remain as strings for Plotly Express)\n",
    "tasks_data = [\n",
    "    {\"Task\": \"Project Start\", \"Start\": '2025-01-01', \"Finish\": '2025-01-01'},\n",
    "    {\"Task\": \"Phase 1: Design\", \"Start\": '2025-01-05', \"Finish\": '2025-01-20'},\n",
    "    {\"Task\": \"Phase 2: Development\", \"Start\": '2025-01-25', \"Finish\": '2025-03-15'},\n",
    "    {\"Task\": \"Phase 3: Testing\", \"Start\": '2025-03-20', \"Finish\": '2025-04-10'},\n",
    "    {\"Task\": \"Project End\", \"Start\": '2025-04-15', \"Finish\": '2025-04-15'}\n",
    "]\n",
    "\n",
    "# Convert the list of dicts into a Pandas DataFrame\n",
    "df = pd.DataFrame(tasks_data)\n",
    "\n",
    "# --- 2. Create the Plotly Figure ---\n",
    "\n",
    "# Plotly Express's timeline function is perfect for Gantt charts\n",
    "fig = px.timeline(\n",
    "    df,\n",
    "    x_start=\"Start\",\n",
    "    x_end=\"Finish\",\n",
    "    y=\"Task\",\n",
    "    title=\"Interactive Project Gantt Chart (Plotly)\",\n",
    "    # Color can be set by a column, e.g., 'Phase' if you added one\n",
    "    color=\"Task\",\n",
    "    # You can set the hover data that appears when hovering over a bar\n",
    "    hover_data={'Start': '|%Y-%m-%d', 'Finish': '|%Y-%m-%d'}\n",
    ")\n",
    "\n",
    "# Optional: Customize layout for better appearance\n",
    "fig.update_yaxes(autorange=\"reversed\") # Display tasks from top to bottom\n",
    "fig.update_layout(xaxis_title=\"Date\")\n",
    "\n",
    "\n",
    "# --- 3. Export Directly to HTML ---\n",
    "\n",
    "# Plotly figures export directly to a standalone, interactive HTML file.\n",
    "fig.write_html(\"index.html\", include_plotlyjs='cdn')\n",
    "\n",
    "# Note: fig.show() can be used to display the chart in a notebook/browser instantly.\n",
    "# fig.show()\n",
    "\n",
    "print(\"Successfully created 'index.html' with the interactive Plotly Gantt chart.\")\n",
    "print(\"The file is ready for embedding in your Socrata/ArcGIS Dashboard.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35e92b92-f725-48e7-8c4c-fd26b9bb8d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotly Gantt chart generated successfully as 'permit_timeline.html'.\n",
      "This file can now be pushed to GitHub Pages for live embedding.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "# --- 1. Define Data and Date Columns ---\n",
    "\n",
    "# The original date columns provided by the user\n",
    "DATE_COLUMNS = [\n",
    "    'Submitted Date',\n",
    "    'Communication Start Date',\n",
    "    'Initial Assessment Date',\n",
    "    'Review Start Date',\n",
    "    'Final Resolution Date',\n",
    "    'Expiration Date'\n",
    "]\n",
    "\n",
    "# Create a dummy DataFrame mimicking your real-world data structure.\n",
    "# NOTE: The Project IDs now reflect the six specific projects you listed.\n",
    "data = \"\"\"\n",
    "Permit ID,Project ID,Submitted Date,Communication Start Date,Initial Assessment Date,Review Start Date,Final Resolution Date,Expiration Date\n",
    "P101,Bainbridge,2025-01-01,2025-01-05,2025-01-10,2025-01-20,2025-02-05,2025-02-15\n",
    "P102,Burnt Hill Farm,2025-01-15,2025-01-20,2025-02-01,2025-02-15,2025-03-01,2025-03-15\n",
    "P104,Loch Raven,2025-03-01,2025-03-10,2025-03-20,2025-04-01,2025-04-10,2025-04-30\n",
    "P105,Pimlico,2025-03-15,2025-03-20,2025-03-25,2025-04-05,2025-04-15,2025-05-01\n",
    "P106,Quantum,2025-04-01,2025-04-05,2025-04-15,2025-04-25,2025-05-05,2025-05-15\n",
    "P107,SBY Market,2025-04-10,2025-04-15,2025-04-20,2025-05-01,2025-05-10,2025-05-20\n",
    "P108,Loch Raven,2025-04-20,2025-04-25,2025-05-01,2025-05-10,2025-05-20,2025-05-30\n",
    "\"\"\"\n",
    "df_raw = pd.read_csv(io.StringIO(data))\n",
    "\n",
    "\n",
    "# --- 2. Data Preparation: Convert Dates and Define Activity Names ---\n",
    "\n",
    "# 2a. Convert all date columns to datetime objects\n",
    "for col in DATE_COLUMNS:\n",
    "    df_raw[col] = pd.to_datetime(df_raw[col])\n",
    "\n",
    "# 2b. Define the sequence of activities (Start_Column -> End_Column)\n",
    "# This list dictates the tasks shown on the Gantt chart.\n",
    "activities = [\n",
    "    ('Initial Submission', 'Submitted Date', 'Communication Start Date'),\n",
    "    ('Internal Comms Wait', 'Communication Start Date', 'Initial Assessment Date'),\n",
    "    ('Assessment Phase', 'Initial Assessment Date', 'Review Start Date'),\n",
    "    ('Formal Review Period', 'Review Start Date', 'Final Resolution Date'),\n",
    "    ('Final Approval/Buffer', 'Final Resolution Date', 'Expiration Date')\n",
    "]\n",
    "\n",
    "# --- 3. Restructure Data from Wide to Long Format (The core transformation) ---\n",
    "\n",
    "gantt_data = []\n",
    "\n",
    "# Iterate over every permit (row) in the original DataFrame\n",
    "for index, row in df_raw.iterrows():\n",
    "    permit_id = row['Project ID']\n",
    "    project_id = row['Project ID']\n",
    "\n",
    "    # Create a new row in the gantt_data list for each activity in the sequence\n",
    "    for activity_name, start_col, end_col in activities:\n",
    "        start_date = row[start_col]\n",
    "        end_date = row[end_col]\n",
    "\n",
    "        # Only add the task if both start and end dates exist\n",
    "        if pd.notna(start_date) and pd.notna(end_date) and start_date <= end_date:\n",
    "            gantt_data.append({\n",
    "                'Project ID': project_id,\n",
    "                'Permit ID': permit_id,\n",
    "                'Activity': activity_name,\n",
    "                'Start': start_date,\n",
    "                'Finish': end_date,\n",
    "                'Duration (Days)': (end_date - start_date).days\n",
    "            })\n",
    "\n",
    "# Create the final DataFrame for plotting\n",
    "df_gantt = pd.DataFrame(gantt_data)\n",
    "\n",
    "\n",
    "# --- 4. Create the Plotly Gantt Chart ---\n",
    "\n",
    "fig = px.timeline(\n",
    "    df_gantt,\n",
    "    x_start=\"Start\",\n",
    "    x_end=\"Finish\",\n",
    "    # Y-axis shows the Permit ID, Grouped by Project ID\n",
    "    y=\"Permit ID\",\n",
    "    # Color bars by the specific Activity type\n",
    "    color=\"Activity\",\n",
    "    # Display important details on hover (Quantity/Duration)\n",
    "    hover_name=\"Activity\",\n",
    "    hover_data={\n",
    "        'Start': '|%Y-%m-%d',\n",
    "        'Finish': '|%Y-%m-%d',\n",
    "        'Duration (Days)': True,\n",
    "        'Project ID': True\n",
    "    },\n",
    "    title=\"Permit Processing Timeline (Grouped by Project)\",\n",
    "    template=\"plotly_white\", # Clean, professional look\n",
    ")\n",
    "\n",
    "# Optional: Add grouping by Project ID\n",
    "# We use the Project ID as the facet row to separate the charts vertically by project\n",
    "fig.update_yaxes(\n",
    "    autorange=\"reversed\", # Puts Task 1 at the top\n",
    "    categoryorder=\"array\",\n",
    "    # Sorts the permits first by Project, then by Permit ID\n",
    "    categoryarray=df_gantt.sort_values(by=['Project ID', 'Permit ID'])['Permit ID'].unique()\n",
    ")\n",
    "\n",
    "# Add range slider for easy date filtering (MS Project feature)\n",
    "fig.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeselector=dict(\n",
    "            buttons=list([\n",
    "                dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n",
    "                dict(step=\"all\")\n",
    "            ])\n",
    "        ),\n",
    "        rangeslider=dict(visible=True),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- 5. Export for Live Hosting ---\n",
    "\n",
    "# This creates the self-contained HTML file ready for GitHub Pages/Socrata embed.\n",
    "fig.write_html(\"permit_timeline.html\", include_plotlyjs='cdn')\n",
    "\n",
    "print(\"Plotly Gantt chart generated successfully as 'permit_timeline.html'.\")\n",
    "print(\"This file can now be pushed to GitHub Pages for live embedding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e972ed8b-7436-473f-839c-c26e4eae6975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
