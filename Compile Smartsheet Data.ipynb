{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78ba6a93-4c42-405e-8d97-a7678252ba48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smartsheet\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from socrata_replace.socrata_py_replace import ReplaceBot\n",
    "from secret_data import userpass\n",
    "from datetime import date, timedelta, datetime\n",
    "import holidays as pyholidays\n",
    "import pytz\n",
    "from datetime import date, datetime, timedelta\n",
    "import holidays as pyholidays \n",
    "\n",
    "\n",
    "SMARTSHEET_ACCESS_TOKEN = \"74xq6QRJHXtN4VdRbwCl9rJeznxjgBcKEPJeJ\"\n",
    "try:\n",
    "    smartsheet_client = smartsheet.Smartsheet(SMARTSHEET_ACCESS_TOKEN)\n",
    "except Exception as e:\n",
    "    print(f\"Details: {e}\")\n",
    "    exit()\n",
    "\n",
    "def get_sheet_data(sheet_id):\n",
    "    \"\"\"\n",
    "    Retrieves the full row and cell data for a specific sheet ID and returns it as a pandas DataFrame.\n",
    "    Modified to correctly aggregate row data and skip empty rows.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sheet_object = smartsheet_client.Sheets.get_sheet(sheet_id)\n",
    "    except smartsheet.exceptions.ApiError as e:\n",
    "        print(e.error.message)\n",
    "        return pd.DataFrame()\n",
    "    print(f\"\\n--- Processing Sheet: {sheet_object.name} (ID: {sheet_id}) ---\")\n",
    "\n",
    "    # 1. Get Column Mapping \n",
    "    column_map = {col.id: col.title for col in sheet_object.columns}\n",
    "    column_titles = list(column_map.values())\n",
    "        \n",
    "    all_rows_data = []\n",
    "        \n",
    "    for row in sheet_object.rows:\n",
    "        row_data = {}\n",
    "        has_data = False\n",
    "        \n",
    "        for cell in row.cells:\n",
    "            column_title = column_map.get(cell.column_id, \"Unknown Column\")\n",
    "                \n",
    "            # Check for a display value first, then fallback to the raw value\n",
    "            value = cell.display_value if cell.display_value is not None else cell.value\n",
    "                \n",
    "            row_data[column_title] = value\n",
    "            \n",
    "            # Check if the cell has a value to skip entirely blank rows\n",
    "            if value is not None and value != '':\n",
    "                has_data = True\n",
    "                \n",
    "        if has_data:\n",
    "            all_rows_data.append(row_data)\n",
    "        \n",
    "    print(f\"Total NON-BLANK rows added to DataFrame: {len(all_rows_data)}\")\n",
    "        \n",
    "    df = pd.DataFrame(all_rows_data, columns=column_titles)\n",
    "        \n",
    "    df['Sheet Name'] = sheet_object.name\n",
    "    df['Sheet ID'] = sheet_id\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68a55653-bbaa-4a74-96fa-86fb3714d54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sheet_id_by_name(sheet_name):\n",
    "    \"\"\"\n",
    "    Finds the ID of a sheet given its name by listing all accessible sheets.\n",
    "    Returns the Sheet ID (integer) or None if not found.\n",
    "    \"\"\"\n",
    "    if not sheet_name: return None\n",
    "    \n",
    "    try:\n",
    "        response = smartsheet_client.Sheets.list_sheets(include_all=True)\n",
    "        for sheet in response.data:\n",
    "            if sheet.name.strip() == sheet_name.strip(): # Use .strip() for robust matching\n",
    "                return sheet.id\n",
    "    except smartsheet.exceptions.ApiError as e:\n",
    "        print(f\"API Error finding sheet ID for '{sheet_name}': {e.error.message}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1dee0005-5fb2-4a9f-875b-a3fb14831ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Sheet: Bainbridge Permit Tracking Sheet (ID: 595984821211012) ---\n",
      "Total NON-BLANK rows added to DataFrame: 20\n",
      "\n",
      "--- Processing Sheet: Burnt Hill Farm Permit Tracking Sheet (ID: 434783269113732) ---\n",
      "Total NON-BLANK rows added to DataFrame: 0\n",
      "\n",
      "--- Processing Sheet: Loch Raven Permit Tracking Sheet (ID: 8555094548107140) ---\n",
      "Total NON-BLANK rows added to DataFrame: 2\n",
      "\n",
      "--- Processing Sheet: Pimlico Permit Tracking Sheet (ID: 8603266901299076) ---\n",
      "Total NON-BLANK rows added to DataFrame: 12\n",
      "\n",
      "--- Processing Sheet: Quantum Permit Tracking Sheet (ID: 2274508036591492) ---\n",
      "Total NON-BLANK rows added to DataFrame: 28\n",
      "\n",
      "--- Processing Sheet: SBY Market Permit Tracking Sheet (ID: 6312015061536644) ---\n",
      "Total NON-BLANK rows added to DataFrame: 9\n",
      "\n",
      "==================================================\n",
      "✅ Compilation Complete! Total Sheets Compiled: 5\n",
      "Final DataFrame shape: (71, 31)\n",
      "✅ Successfully saved DataFrame to 'compiled_smartsheet_data.csv'\n",
      "==================================================\n",
      "\n",
      "Processing column: Submitted Date\n",
      "\n",
      "Processing column: Communication Start Date\n",
      "\n",
      "Processing column: Initial Assessment Date\n",
      "\n",
      "Processing column: Review Start Date\n",
      "\n",
      "Processing column: Final Resolution Date\n",
      "\n",
      "Processing column: Expiration Date\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "all_dfs = []\n",
    "csv_name = 'Sheet Names.csv'\n",
    "df_names = pd.read_csv(csv_name)\n",
    "output_file_name = 'compiled_smartsheet_data.csv'\n",
    "\n",
    "for names in df_names['Sheet Name']:\n",
    "    sheet_id = get_sheet_id_by_name(names)\n",
    "    if sheet_id:\n",
    "        current_df = get_sheet_data(sheet_id)\n",
    "        if not current_df.empty:\n",
    "            all_dfs.append(current_df)\n",
    "if all_dfs:\n",
    "    final_compiled_df = pd.concat(all_dfs, ignore_index=True, sort=False)\n",
    "    final_compiled_df.fillna('', inplace=True)\n",
    "    final_compiled_df['Duration'] = final_compiled_df['Duration'].replace('', np.nan)\n",
    "    \n",
    "    final_compiled_df['Duration_Cleaned'] = final_compiled_df['Duration'].str.replace('d', '', regex=False)\n",
    "    final_compiled_df['Duration_Days'] = pd.to_numeric(final_compiled_df['Duration_Cleaned'], errors='coerce')\n",
    "    final_compiled_df['Duration_Days'] = final_compiled_df['Duration_Days'].astype('Int64')\n",
    "    final_compiled_df['Duration']= final_compiled_df['Duration_Days']\n",
    "    final_compiled_df = final_compiled_df.drop(['Duration_Days', 'Duration_Cleaned'], axis=1)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"✅ Compilation Complete! Total Sheets Compiled: {len(all_dfs)}\")\n",
    "    print(f\"Final DataFrame shape: {final_compiled_df.shape}\")\n",
    "    print(f\"✅ Successfully saved DataFrame to '{output_file_name}'\")\n",
    "    print(\"=\"*50)\n",
    "else:\n",
    "    print(\"\\n--- No sheets were successfully compiled. ---\")\n",
    "\n",
    "\n",
    "# The Eastern Timezone name for pytz, which handles both EST and EDT (Daylight Saving)\n",
    "TARGET_TZ = 'US/Eastern'\n",
    "\n",
    "date_columns = [\n",
    "    'Submitted Date',\n",
    "    'Communication Start Date',\n",
    "    'Initial Assessment Date',\n",
    "    'Review Start Date',\n",
    "    'Final Resolution Date',\n",
    "    'Expiration Date'\n",
    "]\n",
    "\n",
    "for col in date_columns:\n",
    "    print(f\"\\nProcessing column: {col}\")\n",
    "   \n",
    "    final_compiled_df[col] = pd.to_datetime(\n",
    "        final_compiled_df[col],\n",
    "        errors='coerce',\n",
    "        utc=True \n",
    "    )\n",
    "    if not pd.api.types.is_datetime64_any_dtype(final_compiled_df[col]):\n",
    "        print(f\"Column '{col}' failed to convert to a datetime dtype or is missing a value. Skipping.\")\n",
    "        final_compiled_df[col] = np.nan\n",
    "        continue\n",
    "\n",
    "    final_compiled_df[col] = final_compiled_df[col].dt.tz_convert(TARGET_TZ)\n",
    "        \n",
    "    date_only_series = final_compiled_df[col].dt.date.apply(lambda x: x.isoformat() if pd.notna(x) else np.nan)\n",
    "\n",
    "    final_compiled_df[col] = final_compiled_df[col].apply(\n",
    "        lambda x: x.isoformat() if pd.notna(x) else np.nan\n",
    "    )\n",
    "final_compiled_df.to_csv(output_file_name, index=False, encoding='utf-8')\n",
    "print(\"\\nScript finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a765a947-0ff0-4f71-8512-244ef9d6c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portal = \"data.maryland.gov\"\n",
    "uid='b4mc-xw4p'\n",
    "rb = ReplaceBot(False, data_folder=\"\", filename=output_file_name, socrata_server=portal)\n",
    "rb.upload_replacement(uid, 'private', filename=output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ebc98f30-eedd-4bf0-ae1a-0bf490448ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "import holidays as pyholidays # Assuming you are using the 'holidays' library\n",
    "\n",
    "def count_maryland_business_days(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Calculates the total number of business days (Mon-Fri, excluding \n",
    "    US federal and Maryland state holidays) between a start_date and an end_date (inclusive of end_date).\n",
    "\n",
    "    :param start_date: The date to start the calculation from (datetime.date object).\n",
    "    :param end_date: The date to end the calculation at (datetime.date object).\n",
    "    :return: The number of business days in the range.\n",
    "    \"\"\"\n",
    "    # NOTE: Assuming start_date and end_date are already datetime.date objects \n",
    "    # as per the DataFrame preparation below.\n",
    "\n",
    "    # Ensure start and end dates are valid for calculation\n",
    "    if not (isinstance(start_date, date) and isinstance(end_date, date)):\n",
    "        return np.nan\n",
    "    \n",
    "    # Handle NaT values passed from pandas\n",
    "    if pd.isna(start_date) or pd.isna(end_date):\n",
    "        return np.nan\n",
    "\n",
    "    # If the process isn't complete, return 0 or NaN\n",
    "    if start_date > end_date:\n",
    "        return 0\n",
    "\n",
    "    # 1. Get the list of Maryland holidays within the required year range\n",
    "    md_holidays = pyholidays.US(state='MD', years=range(start_date.year, end_date.year + 2))\n",
    "\n",
    "    business_day_count = 0\n",
    "    current_date = start_date\n",
    "\n",
    "    # 2. Loop through each day from start_date up to and including end_date\n",
    "    while current_date <= end_date:\n",
    "        \n",
    "        # Check 1: Is the current day a weekend day? (Saturday=5, Sunday=6)\n",
    "        is_weekend = current_date.weekday() >= 5\n",
    "        \n",
    "        # Check 2: Is the current day a holiday?\n",
    "        is_holiday = current_date in md_holidays\n",
    "        \n",
    "        # Check 3: If it's NOT a weekend AND NOT a holiday, it's a business day.\n",
    "        if not is_weekend and not is_holiday:\n",
    "            business_day_count += 1\n",
    "        \n",
    "        # Move to the next day\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return business_day_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aee113f9-365c-4c82-bc1c-ae387b1f8cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting business day calculations against today's date...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m     new_col_name \u001b[38;5;241m=\u001b[39m start_col\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_business_days_to_today\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# 2. Use .apply(..., axis=1) to pass the start date for each row\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     final_compiled_df[new_col_name] \u001b[38;5;241m=\u001b[39m final_compiled_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: count_maryland_business_days(\n\u001b[0;32m     33\u001b[0m             \u001b[38;5;66;03m# Pass the START DATE: The date from the current row/column.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;66;03m# We use .date() to convert the Pandas Datetime object to a Python date object.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m             row[start_col]\u001b[38;5;241m.\u001b[39mdate(), \n\u001b[0;32m     36\u001b[0m             \u001b[38;5;66;03m# Pass the END DATE: Today's fixed date\u001b[39;00m\n\u001b[0;32m     37\u001b[0m             date\u001b[38;5;241m.\u001b[39mtoday()\n\u001b[0;32m     38\u001b[0m         )\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;66;03m# Use a quick check for NaT values before calling the function\u001b[39;00m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(row[start_col]) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, \n\u001b[0;32m     41\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     42\u001b[0m     )\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Calculated \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_col_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBusiness day calculation loop complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[99], line 35\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     28\u001b[0m     new_col_name \u001b[38;5;241m=\u001b[39m start_col\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Date\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_business_days_to_today\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# 2. Use .apply(..., axis=1) to pass the start date for each row\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     final_compiled_df[new_col_name] \u001b[38;5;241m=\u001b[39m final_compiled_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m     32\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: count_maryland_business_days(\n\u001b[0;32m     33\u001b[0m             \u001b[38;5;66;03m# Pass the START DATE: The date from the current row/column.\u001b[39;00m\n\u001b[0;32m     34\u001b[0m             \u001b[38;5;66;03m# We use .date() to convert the Pandas Datetime object to a Python date object.\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m             row[start_col]\u001b[38;5;241m.\u001b[39mdate(), \n\u001b[0;32m     36\u001b[0m             \u001b[38;5;66;03m# Pass the END DATE: Today's fixed date\u001b[39;00m\n\u001b[0;32m     37\u001b[0m             date\u001b[38;5;241m.\u001b[39mtoday()\n\u001b[0;32m     38\u001b[0m         )\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;66;03m# Use a quick check for NaT values before calling the function\u001b[39;00m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mnotna(row[start_col]) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan, \n\u001b[0;32m     41\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     42\u001b[0m     )\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Calculated \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_col_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBusiness day calculation loop complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date # date.today() comes from here\n",
    "\n",
    "# Assuming date_columns is defined and ALL dates have been successfully \n",
    "# converted to timezone-aware Pandas Datetime objects (e.g., Eastern Time).\n",
    "\n",
    "# --- 1. Define the List of START Dates for the calculation ---\n",
    "# You want the calculation for ALL columns listed, up to today.\n",
    "start_date_columns = [\n",
    "    'Submitted Date',\n",
    "    'Communication Start Date',\n",
    "    'Initial Assessment Date',\n",
    "    'Review Start Date',\n",
    "    'Final Resolution Date',\n",
    "    'Expiration Date' \n",
    "    # NOTE: You must include only columns that make sense as START dates\n",
    "]\n",
    "\n",
    "print(\"Starting business day calculations against today's date...\")\n",
    "\n",
    "# --- 2. Loop and Apply the Custom Function (axis=1 is crucial) ---\n",
    "\n",
    "for start_col in start_date_columns:\n",
    "    \n",
    "    # 1. Define the new column name\n",
    "    # Example: 'Submitted Date' -> 'submitted_date_business_days_to_today'\n",
    "    new_col_name = start_col.replace(' Date', '').replace(' ', '_').lower() + \"_business_days_to_today\"\n",
    "    \n",
    "    # 2. Use .apply(..., axis=1) to pass the start date for each row\n",
    "    final_compiled_df[new_col_name] = final_compiled_df.apply(\n",
    "        lambda row: count_maryland_business_days(\n",
    "            # Pass the START DATE: The date from the current row/column.\n",
    "            # We use .date() to convert the Pandas Datetime object to a Python date object.\n",
    "            row[start_col].date(), \n",
    "            # Pass the END DATE: Today's fixed date\n",
    "            date.today()\n",
    "        )\n",
    "        # Use a quick check for NaT values before calling the function\n",
    "        if pd.notna(row[start_col]) else np.nan, \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Calculated '{new_col_name}'.\")\n",
    "\n",
    "print(\"\\nBusiness day calculation loop complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e463352-7d65-4cf7-ac50-50061f9ed065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda06189-caae-405c-8745-115f370234e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
